from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.pipeline import make_pipeline


def extract_mnemonics(df, field="kw", words=1):
    """Extract only mnemonics for the dataset, excluding additional arguments
    
    Args:
        df: pandas DataFrame
            dataset
        field: str
            name of the field in which mnemonics will be stored
        words: int, default 1
            number of keywords to extract in each instruction
    Returns:
        pandas DataFrame
    """
    dataset = df.copy()
    dataset["kw"] = [" ".join([" ".join(x.split(" ")[:words]) for x in i]) for i in dataset.instructions]
    
    return dataset

def get_ngrams(df, ngrams, start=None, end=None, field="kw"):
    """Sets n-grams for the given dataset using sklearn's CountVectorizer

    Args:
        df: pandas DataFrame
            dataset
        ngrams: tuple
            ranging size of ngrams
        start: int, default None
            number of mnemonics in the beggining of the each observation of field
        end: int, default None
            number of mnemonics in the end of the each observation of field
        field: str, default "kw"
            name of the field to extract n-grams
    Returns:
        vectorized: sparse matrix
            resulting ngram extraction
        vectorizer: CountVectorizer object
            vectorizer operator
    """
    dataset = df.copy()
    if start and end:
        kws = list()
        for command in dataset.kw:
            if len(command) > start + end:
                command = command.split(" ")
                command = command[:start] + (command[-end:] if end > 0 else [])
                kws.append(" ".join(command))
            else:
                kws.append(command) 
    vectorizer = CountVectorizer(analyzer='word', ngram_range=ngrams, lowercase=False)
    vectorized = vectorizer.fit_transform(dataset.kw)
    
    return vectorized, vectorizer

def get_size_count(df):
    """Return features regarding the size of the commands (distinct or not)
    
    Args:
        df: pandas DataFrame
            dataset
    Returns:
        pandas DataFrame containing the new features
    """
    dataset = df.copy()
    dataset["command_count"] = [len(x.split(" ")) for x in dataset.kw]
    dataset["distinct_commands"] = [len(set(x.split(" "))) for x in dataset.kw]
    
    return dataset

def get_word_count(df):
    """Get frequency count and single occurence check for each keyword

    Args:
        df: pandas DataFrame
            dataset
    Returns:
        vectorized: sparse matrix
            resulting ngram extraction
        vectorizer: CountVectorizer object
            vectorizer operator
    """
    dataset = df.copy()
    ngrams, vectorizer = get_ngrams(dataset, ngrams=(1, 1))
    ngrams[ngrams > 0] = 1 # binary encoding
    print("Set of distinct instructions: {}".format(ngrams.shape[1]))

    return ngrams, vectorizer

def get_tfidt(df, target_label="compiler", seed=42):
    """Get the term frequencyâ€“inverse document frequency for the dataset observations
        Note: in this case, the test-train split is performed before the transformation, in order to avoid data-leakage

        Args:
            df: pandas DataFrame
                model to insert in pipeline
            target_label: str, default "compiler"
                target column in dataframe
            seed: int, default 42
                random seed generator
        Returns:
            transformer: TfidfTransformer
            
            X_train: scipy sparse matrix
            
            X_test: scipy sparse matrix

            y_train: pandas Series
            
            y_test: pandas Series

    """
    # source: https://kavita-ganesan.com/tfidftransformer-tfidfvectorizer-usage-differences/
    dataset = df.copy()
    X_train, X_test, y_train, y_test = train_test_split(dataset.kw, dataset[target_label], random_state=seed)

    vectorizer = CountVectorizer()
    X_train = vectorizer.fit_transform(X_train)

    transformer = TfidfTransformer(smooth_idf=True, use_idf=True)
    X_train = transformer.fit_transform(X_train)
    
    X_test = vectorizer.transform(X_test)
    X_test = transformer.transform(X_test)

    return transformer, X_train, X_test, y_train, y_test 