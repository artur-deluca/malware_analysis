import json
import numpy as np
import matplotlib.pyplot as plt

from sklearn.base import TransformerMixin, BaseEstimator
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfTransformer


class MnemonicExtractor(BaseEstimator, TransformerMixin):
    """Extract only mnemonics for the dataset, excluding additional arguments
    
    Args:
        df: pandas DataFrame
            dataset
        field: str
            name of the field in which mnemonics will be stored
        words: int, default 1
            number of keywords to extract in each instruction
    Returns:
        pandas DataFrame
    """
    def __init__(self, words=1):
        self.words = words

    def fit(self, *_):
        return self

    def transform(self, X, *_):
        return [" ".join([" ".join(x.split(" ")[:self.words]) for x in i]) for i in X]

class nGramsExtractor(BaseEstimator, TransformerMixin):
    """Sets n-grams for the given dataset using sklearn's CountVectorizer

    Args:
        df: pandas DataFrame
            dataset
        ngrams: tuple
            ranging size of ngrams
        start: int, default None
            number of mnemonics in the beggining of the each observation of field
        end: int, default None
            number of mnemonics in the end of the each observation of field
        field: str, default "kw"
            name of the field to extract n-grams
    Returns:
        vectorized: sparse matrix
            resulting ngram extraction
        vectorizer: CountVectorizer object
            vectorizer operator
    """
    def __init__(self, ngrams, words=1, start=None, end=None):
        self.ngrams = ngrams
        self.start = start
        self.end = end
        self.words = words

    def fit(self, X, *_):
        kw = MnemonicExtractor(self.words).fit_transform(X)
        if self.start and self.end:
            kws = list()
            for command in kw:
                if len(command) > self.start + self.end:
                    command = command.split(" ")
                    command = command[:self.start] + (command[-self.end:] if self.end > 0 else [])
                    kws.append(" ".join(command))
                else:
                    kws.append(command)
        self.vectorizer = CountVectorizer(analyzer='word', ngram_range=self.ngrams, lowercase=False).fit(kw)
        return self

    def transform(self, X, *_):
        kw = MnemonicExtractor(self.words).fit_transform(X)
        return self.vectorizer.transform(kw)

class nGramsSimplifier(BaseEstimator, TransformerMixin):
    """Sets n-grams for the given dataset using sklearn's CountVectorizer

    Args:
        df: pandas DataFrame
            dataset
        ngrams: tuple
            ranging size of ngrams
        start: int, default None
            number of mnemonics in the beggining of the each observation of field
        end: int, default None
            number of mnemonics in the end of the each observation of field
        field: str, default "kw"
            name of the field to extract n-grams
    Returns:
        vectorized: sparse matrix
            resulting ngram extraction
        vectorizer: CountVectorizer object
            vectorizer operator
    """
    def __init__(self, ngrams, ncolumns, words=1, start=None, end=None):
        self.ngrams = ngrams
        self.start = start
        self.end = end
        self.words = words
        self.ncolumns = ncolumns

    def fit(self, X, y):
        
        important_columns = list()
        y = np.unique(y)
        classes = np.unique(y)

        self.helper = nGramsExtractor(self.ngrams, self.words, self.start, self.end).fit(X)
        ngrams = self.helper.transform(X)

        for n_class in classes:
            occurencies = sorted(
                enumerate(
                    ngrams[np.where(y==n_class)[0]].mean(axis=0).tolist()[0]),
                    reverse=True,
                    key=lambda x: x[1]
            )[:self.ncolumns]
            important_columns.extend([x[0] for x in occurencies])
        self.important_columns = set(important_columns)
        return self

    def transform(self, X, *_):
        return self.helper.transform(X)[:, list(self.important_columns)]

class SizeCountExtractor(BaseEstimator, TransformerMixin):
    """Return features regarding the size of the commands (distinct or not)
    
    Args:
        df: pandas DataFrame
            dataset
    Returns:
        pandas DataFrame containing the new features
    """
    def __init__(self, words=1):
        self.words = words

    def fit(self, *_):
        return self

    def transform(self, X, *_):
        kw = [" ".join([" ".join(x.split(" ")[:self.words]) for x in i]) for i in X]
        command_count = [len(x.split(" ")) for x in kw]
        distinct_commands = [len(set(x.split(" "))) for x in kw]
        return list(zip(command_count, distinct_commands))

class WordCountExtractor(BaseEstimator, TransformerMixin):
    """Get frequency count and single occurence check for each keyword

    Args:
        df: pandas DataFrame
            dataset
    Returns:
        vectorized: sparse matrix
            resulting ngram extraction
        vectorizer: CountVectorizer object
            vectorizer operator
    """

    def fit(self, X, *_):
        self.vectorizer = nGramsExtractor(ngrams=(1,1)).fit(X)
        return self

    def transform(self, X, *_):
        ngrams = self.vectorizer.transform(X)
        ngrams[ngrams > 0] = 1 # binary encoding
        return ngrams

class TfidfExtractor(BaseEstimator, TransformerMixin):
    """Get the term frequencyâ€“inverse document frequency for the dataset observations
        Note: in this case, the test-train split is performed before the transformation, in order to avoid data-leakage

        Args:
            model: sklearn estimator
                model to insert in pipeline
        Returns:
            sklearn pipeline
    """

    def fit(self, X, *_):
        kw = MnemonicExtractor().fit_transform(X)
        self.vectorizer = CountVectorizer().fit(kw)
        self.transformer = TfidfTransformer(smooth_idf=True, use_idf=True).fit(self.vectorizer.transform(kw))
        return self

    def transform(self, X, *_):
        kw = MnemonicExtractor().fit_transform(X)
        return self.transformer.transform(self.vectorizer.transform(kw))
