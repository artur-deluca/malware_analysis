import logging
import pandas as pd
import support

from sklearn.pipeline import make_pipeline
from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV
from sklearn.svm import LinearSVC
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import make_scorer, accuracy_score, matthews_corrcoef, confusion_matrix



SEED = 42
CV_SPLITS = 10
title = "Confusion Matrix: {}"

scoring = {'MCC': make_scorer(matthews_corrcoef), 'Accuracy': make_scorer(accuracy_score)}

dataset = (pd.read_json("./train_dataset.json", lines=True)
        .sample(frac=1, random_state=SEED).
        reset_index(drop=True)
)


if __name__ == "__main__":

    import logging
    logging.basicConfig()
    logging.getLogger().setLevel(logging.INFO)

    ####### first target: optimization degree #######
    target = "opt"
    X_train, X_test, y_train, y_test = train_test_split(dataset.instructions, dataset[target], random_state=SEED)

    logging.info("Initializing first target: {}".format(target))
    model = make_pipeline(
        support.nGramsExtractor(ngrams=(4,4), words=2),
        LinearSVC()
    )

    logging.info("Pipeline ready")
    # set parameters for grid search
    parameters = {'linearsvc__C':[1, 10], "linearsvc__penalty": ("l1", "l2"), "linearsvc__class_weight": ("balanced", {"H":1.5, "L":1})}

    logging.info("Starting grid search cross validation")
    results = GridSearchCV(model, parameters, cv=5, error_score=0, scoring=scoring, refit="MCC").fit(dataset.instructions, dataset[target])
    
    logging.info("Grid search successful, saving")
    support.save_grid_search(results.cv_results_, "./results/optimizer_degree/parameter_tuning/parameter_tuning.json")

    # plot confusion matrix for best configuration
    logging.info("Saving confusion matrix of best configuration found")
    results.best_estimator_.fit(X_train, y_train)
    name = "Linear SVM ({})".format(" ".join(str(x) for x in results.best_params_.values()))
    support.plot_confusion_matrix(y_test, results.best_estimator_.predict(X_test), classes=dataset.opt.unique(), title=title.format(name))


    ####### second target: compiler provenance #######
    target = "compiler"
    X_train, X_test, y_train, y_test = train_test_split(dataset.instructions, dataset[target], random_state=SEED)

    logging.info("Initializing first target: {}".format(target))
    model = make_pipeline(
        support.nGramsExtractor(ngrams=(4,4), words=2),
        MultinomialNB()
    )

    logging.info("Pipeline ready")
    # set parameters for grid search
    parameters = {"multinomialnb__alpha": [0,1,1.5]}

    logging.info("Starting grid search cross validation")
    results = GridSearchCV(model, parameters, cv=5, error_score=0, scoring=scoring, refit="MCC").fit(dataset.instructions, dataset[target])
    
    logging.info("Grid search successful, saving")
    support.save_grid_search(results.cv_results_, "./results/compiler_provenance/parameter_tuning/parameter_tuning")

    # plot confusion matrix for best configuration
    logging.info("Saving confusion matrix of best configuration found")
    results.best_estimator_.fit(X_train, y_train)
    name = "Naive Bayes ({})".format(" ".join(str(x) for x in results.best_params_.values()))
    support.plot_confusion_matrix(y_test, results.best_estimator_.predict(X_test), classes=dataset.opt.unique(), title=title.format(name))                                        